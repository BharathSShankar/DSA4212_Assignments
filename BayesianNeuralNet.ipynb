{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BharathSShankar/DSA4212_Assignments/blob/bharath-exp/BayesianNeuralNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist torchmetrics\n",
        "!python -m medmnist download"
      ],
      "metadata": {
        "id": "39qHekF2tOcn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823cd363-81ff-4374-f4d0-af49a17b0f0f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting medmnist\n",
            "  Downloading medmnist-2.2.1-py3-none-any.whl (21 kB)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from medmnist) (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from medmnist) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from medmnist) (1.5.3)\n",
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from medmnist) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from medmnist) (4.65.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from medmnist) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from medmnist) (0.15.1+cu118)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from medmnist) (8.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->medmnist) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->medmnist) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->medmnist) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->medmnist) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->medmnist) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->medmnist) (3.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->medmnist) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->medmnist) (16.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from fire->medmnist) (2.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->medmnist) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->medmnist) (1.10.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->medmnist) (2.25.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->medmnist) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->medmnist) (2023.4.12)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->medmnist) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->medmnist) (1.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->medmnist) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->medmnist) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->medmnist) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->medmnist) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->medmnist) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->medmnist) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->medmnist) (1.3.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116952 sha256=621a8b26873e6797ca77fb806810b58735b4c9a3351337b6a6c74e76951cdd7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/f1/89/b9ea2bf8f80ec027a88fef1d354b3816b4d3d29530988972f6\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, torchmetrics, medmnist\n",
            "Successfully installed fire-0.5.0 medmnist-2.2.1 torchmetrics-0.11.4\n",
            "Downloading pathmnist...\n",
            "Downloading https://zenodo.org/record/6496656/files/pathmnist.npz?download=1 to /root/.medmnist/pathmnist.npz\n",
            "100% 205615438/205615438 [01:53<00:00, 1814791.85it/s]\n",
            "Downloading chestmnist...\n",
            "Downloading https://zenodo.org/record/6496656/files/chestmnist.npz?download=1 to /root/.medmnist/chestmnist.npz\n",
            "100% 82802576/82802576 [00:49<00:00, 1674644.40it/s]\n",
            "Downloading dermamnist...\n",
            "Downloading https://zenodo.org/record/6496656/files/dermamnist.npz?download=1 to /root/.medmnist/dermamnist.npz\n",
            "100% 19725078/19725078 [00:07<00:00, 2668070.33it/s]\n",
            "Downloading octmnist...\n",
            "Downloading https://zenodo.org/record/6496656/files/octmnist.npz?download=1 to /root/.medmnist/octmnist.npz\n",
            "100% 54938180/54938180 [01:43<00:00, 532458.74it/s]\n",
            "Downloading pneumoniamnist...\n",
            "Downloading https://zenodo.org/record/6496656/files/pneumoniamnist.npz?download=1 to /root/.medmnist/pneumoniamnist.npz\n",
            "100% 4170669/4170669 [00:07<00:00, 545168.73it/s]\n",
            "Downloading retinamnist...\n",
            "Downloading https://zenodo.org/record/6496656/files/retinamnist.npz?download=1 to /root/.medmnist/retinamnist.npz\n",
            "100% 3291041/3291041 [00:06<00:00, 535135.17it/s]\n",
            "Downloading breastmnist...\n",
            "Downloading https://zenodo.org/record/6496656/files/breastmnist.npz?download=1 to /root/.medmnist/breastmnist.npz\n",
            "100% 559580/559580 [00:01<00:00, 516024.26it/s]\n",
            "Downloading bloodmnist...\n",
            "Downloading https://zenodo.org/record/6496656/files/bloodmnist.npz?download=1 to /root/.medmnist/bloodmnist.npz\n",
            "100% 35461855/35461855 [01:06<00:00, 535549.27it/s]\n",
            "Downloading tissuemnist...\n",
            "Downloading https://zenodo.org/record/6496656/files/tissuemnist.npz?download=1 to /root/.medmnist/tissuemnist.npz\n",
            "100% 124962739/124962739 [01:33<00:00, 1341564.15it/s]\n",
            "Downloading organamnist...\n",
            "Downloading https://zenodo.org/record/6496656/files/organamnist.npz?download=1 to /root/.medmnist/organamnist.npz\n",
            "100% 38247903/38247903 [01:11<00:00, 533569.91it/s]\n",
            "Downloading organcmnist...\n",
            "Downloading https://zenodo.org/record/6496656/files/organcmnist.npz?download=1 to /root/.medmnist/organcmnist.npz\n",
            "100% 15527535/15527535 [00:29<00:00, 531809.17it/s]\n",
            "Downloading organsmnist...\n",
            "Downloading https://zenodo.org/record/6496656/files/organsmnist.npz?download=1 to /root/.medmnist/organsmnist.npz\n",
            "100% 16528536/16528536 [00:21<00:00, 767629.40it/s] \n",
            "Downloading organmnist3d...\n",
            "Downloading https://zenodo.org/record/6496656/files/organmnist3d.npz?download=1 to /root/.medmnist/organmnist3d.npz\n",
            "100% 32657407/32657407 [01:00<00:00, 539387.86it/s]\n",
            "Downloading nodulemnist3d...\n",
            "Downloading https://zenodo.org/record/6496656/files/nodulemnist3d.npz?download=1 to /root/.medmnist/nodulemnist3d.npz\n",
            "100% 29299364/29299364 [00:54<00:00, 534867.10it/s]\n",
            "Downloading adrenalmnist3d...\n",
            "Downloading https://zenodo.org/record/6496656/files/adrenalmnist3d.npz?download=1 to /root/.medmnist/adrenalmnist3d.npz\n",
            "100% 276833/276833 [00:00<00:00, 574100.81it/s]\n",
            "Downloading fracturemnist3d...\n",
            "Downloading https://zenodo.org/record/6496656/files/fracturemnist3d.npz?download=1 to /root/.medmnist/fracturemnist3d.npz\n",
            "100% 3278419/3278419 [00:06<00:00, 535059.53it/s]\n",
            "Downloading vesselmnist3d...\n",
            "Downloading https://zenodo.org/record/6496656/files/vesselmnist3d.npz?download=1 to /root/.medmnist/vesselmnist3d.npz\n",
            "100% 398373/398373 [00:00<00:00, 467954.48it/s]\n",
            "Downloading synapsemnist3d...\n",
            "Downloading https://zenodo.org/record/6496656/files/synapsemnist3d.npz?download=1 to /root/.medmnist/synapsemnist3d.npz\n",
            "100% 38034583/38034583 [01:01<00:00, 621275.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm, trange"
      ],
      "metadata": {
        "id": "lmmUvxZDmRz_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ],
      "metadata": {
        "id": "5FJe6S9YmRwg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = 'pathmnist'\n",
        "# data_flag = 'breastmnist'\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 128\n",
        "lr = 0.001\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n"
      ],
      "metadata": {
        "id": "0id9rD1omRqQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
        "\n",
        "pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "VhsA3s83hYWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd256c78-62dd-44bd-b34c-111b6f72af54"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/pathmnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/pathmnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/pathmnist.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "PI = 0.5\n",
        "SIGMA_1 = torch.FloatTensor([np.exp(1)]).to(DEVICE)\n",
        "SIGMA_2 = torch.FloatTensor([np.exp(-4)]).to(DEVICE)"
      ],
      "metadata": {
        "id": "IkukrBGf17Sx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Gaussian(object):\n",
        "    def __init__(self, mu, rho):\n",
        "        super().__init__()\n",
        "        self.mu = mu\n",
        "        self.rho = rho\n",
        "        self.normal = torch.distributions.Normal(0,1)\n",
        "    \n",
        "    @property\n",
        "    def sigma(self):\n",
        "        return torch.log1p(torch.exp(self.rho))\n",
        "    \n",
        "    def sample(self):\n",
        "        epsilon = self.normal.sample(self.rho.size()).to(DEVICE)\n",
        "        return self.mu + self.sigma * epsilon\n",
        "    \n",
        "    def log_prob(self, input):\n",
        "        return (-np.log(np.sqrt(2 * np.pi))\n",
        "                - torch.log(self.sigma)\n",
        "                - ((input - self.mu) ** 2) / (2 * self.sigma ** 2)).sum()"
      ],
      "metadata": {
        "id": "KThYGJYb16lN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScaleMixtureGaussian(object):\n",
        "    def __init__(self, pi, sigma1, sigma2):\n",
        "        super().__init__()\n",
        "        self.pi = pi\n",
        "        self.sigma1 = sigma1\n",
        "        self.sigma2 = sigma2\n",
        "        self.gaussian1 = torch.distributions.Normal(0,sigma1)\n",
        "        self.gaussian2 = torch.distributions.Normal(0,sigma2)\n",
        "    \n",
        "    def log_prob(self, input):\n",
        "        prob1 = torch.exp(self.gaussian1.log_prob(input))\n",
        "        prob2 = torch.exp(self.gaussian2.log_prob(input))\n",
        "        return (torch.log(self.pi * prob1 + (1-self.pi) * prob2)).sum()"
      ],
      "metadata": {
        "id": "Gik9nYhW2TvA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BayesianDense(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-0.1, 0.1))\n",
        "        self.weight_rho = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-7,-5))\n",
        "        self.weight = Gaussian(self.weight_mu, self.weight_rho)\n",
        "\n",
        "        self.bias_mu = nn.Parameter(torch.Tensor(out_features).uniform_(-0.1, 0.1))\n",
        "        self.bias_rho = nn.Parameter(torch.Tensor(out_features).uniform_(-7,-5))\n",
        "        self.bias = Gaussian(self.bias_mu, self.bias_rho)\n",
        "\n",
        "        self.weight_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
        "        self.bias_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
        "        self.log_prior = 0\n",
        "        self.log_variational_posterior = 0\n",
        "\n",
        "    def forward(self, input, sample=False, calculate_log_probs=False):\n",
        "        if self.training or sample:\n",
        "            weight = self.weight.sample()\n",
        "            bias = self.bias.sample()\n",
        "        else:\n",
        "            weight = self.weight.mu\n",
        "            bias = self.bias.mu\n",
        "        if self.training or calculate_log_probs:\n",
        "            self.log_prior = self.weight_prior.log_prob(weight) + self.bias_prior.log_prob(bias)\n",
        "            self.log_variational_posterior = self.weight.log_prob(weight) + self.bias.log_prob(bias)\n",
        "        else:\n",
        "            self.log_prior, self.log_variational_posterior = 0, 0\n",
        "\n",
        "        return F.linear(input, weight, bias)\n",
        "    \n",
        "    def kl_loss(self):\n",
        "        kl = self.weight_prior.log_prob(self.weight.mu) - self.weight.log_prob(self.weight.mu)\n",
        "        kl += self.bias_prior.log_prob(self.bias.mu) - self.bias.log_prob(self.bias.mu)\n",
        "        return kl.sum()"
      ],
      "metadata": {
        "id": "h6JucxETUk-4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BayesianConv2D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, k_size):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.k_size = k_size\n",
        "\n",
        "        self.weight_mu = nn.Parameter(torch.Tensor(out_channels, in_channels, k_size, k_size).uniform_(-0.1, 0.1))\n",
        "        self.weight_rho = nn.Parameter(torch.Tensor(out_channels, in_channels, k_size,k_size).uniform_(-7,-5))\n",
        "        self.weight = Gaussian(self.weight_mu, self.weight_rho)\n",
        "\n",
        "        self.bias_mu = nn.Parameter(torch.Tensor(out_channels).uniform_(-0.1, 0.1))\n",
        "        self.bias_rho = nn.Parameter(torch.Tensor(out_channels).uniform_(-7,-5))\n",
        "        self.bias = Gaussian(self.bias_mu, self.bias_rho)\n",
        "\n",
        "        self.weight_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
        "        self.bias_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
        "        self.log_prior = 0\n",
        "        self.log_variational_posterior = 0\n",
        "\n",
        "    def forward(self, input, sample=False, calculate_log_probs=False):\n",
        "        if self.training or sample:\n",
        "            weight = self.weight.sample()\n",
        "            bias = self.bias.sample()\n",
        "        else:\n",
        "            weight = self.weight.mu\n",
        "            bias = self.bias.mu\n",
        "        if self.training or calculate_log_probs:\n",
        "            self.log_prior = self.weight_prior.log_prob(weight) + self.bias_prior.log_prob(bias)\n",
        "            self.log_variational_posterior = self.weight.log_prob(weight) + self.bias.log_prob(bias)\n",
        "        else:\n",
        "            self.log_prior, self.log_variational_posterior = 0, 0\n",
        "\n",
        "        return F.conv2d(input, weight, bias)\n",
        "    \n",
        "    def kl_loss(self):\n",
        "        kl = self.weight_prior.log_prob(self.weight.mu) - self.weight.log_prob(self.weight.mu)\n",
        "        kl += self.bias_prior.log_prob(self.bias.mu) - self.bias.log_prob(self.bias.mu)\n",
        "        return kl.sum()"
      ],
      "metadata": {
        "id": "Teuk8UqS3Q80"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BayesianNeuralNetFC(nn.Module):\n",
        "    def __init__(self, layers_dims, input_size, n_classes):\n",
        "        super().__init__()\n",
        "        self.inputLayer = BayesianDense(input_size, layers_dims[0])\n",
        "        layer_list = []\n",
        "        for i in range(1, len(layers_dims)):\n",
        "            layer_list.append(BayesianDense(layers_dims[i - 1], layers_dims[i]))\n",
        "        self.linears = nn.ModuleList(layer_list)\n",
        "        self.outputLayer = BayesianDense(layers_dims[-1], n_classes)\n",
        "    \n",
        "    def forward(self, input, sample=False, calculate_log_probs=False):\n",
        "        x = nn.Flatten()(input)\n",
        "        x = self.inputLayer(x, sample, calculate_log_probs)\n",
        "        x = F.relu(x)\n",
        "        x = nn.Dropout(p=0.1)(x)\n",
        "        for layer in self.linears:\n",
        "            x = layer(x, sample, calculate_log_probs)\n",
        "            x = F.relu(x)\n",
        "            x = nn.Dropout(p=0.1)(x)\n",
        "        x = self.outputLayer(x)\n",
        "        return x\n",
        "\n",
        "    def kl_loss(self):\n",
        "        kl = 0.0\n",
        "        for layer in self.linears:\n",
        "            kl += layer.kl_loss()\n",
        "        kl += self.inputLayer.kl_loss()\n",
        "        kl += self.outputLayer.kl_loss()\n",
        "        return kl"
      ],
      "metadata": {
        "id": "QwlML0Db4kPg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bayesian_net(net, train_loader, test_loader, is_bayes=False, n_epochs=3, lr=3e-4, log_interval=10, beta=1e-7):\n",
        "    # Define loss function and optimizer\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "    # Move model to device\n",
        "    net.to(DEVICE)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(n_epochs):\n",
        "        # Training mode\n",
        "        net.train()\n",
        "        train_loss = 0\n",
        "        ce_loss = 0\n",
        "        kl_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with tqdm(train_loader, desc=f\"Epoch {epoch+1}\") as t:\n",
        "            for batch_idx, (data, target) in enumerate(t):\n",
        "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "                # Forward pass\n",
        "                optimizer.zero_grad()\n",
        "                outputs = net(data)\n",
        "\n",
        "                # Compute loss and update model\n",
        "                if is_bayes:\n",
        "                    ce_loss = loss_func(outputs, target.T[0])\n",
        "                    kl_loss = net.kl_loss()\n",
        "                    loss = ce_loss - beta * kl_loss\n",
        "                else:\n",
        "                    loss = loss_func(outputs, target.T[0])\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Update training statistics\n",
        "                train_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += data.shape[0]\n",
        "                correct += predicted.eq(target.T[0]).sum().item()\n",
        "\n",
        "                # Log training progress\n",
        "                if batch_idx % log_interval == 0:\n",
        "                    train_acc = correct / total\n",
        "                    train_loss /= log_interval\n",
        "                    ce_loss /= log_interval\n",
        "                    kl_loss /= log_interval\n",
        "                    t.set_postfix(ce_loss=f\"{ce_loss:.6f}\", kl_loss=f\"{kl_loss:.6f}\", loss=f\"{train_loss:.6f}\", accuracy=f\"{train_acc:.2f}\")\n",
        "                    train_loss = 0\n",
        "                    ce_loss = 0\n",
        "                    kl_loss = 0\n",
        "                    correct = 0\n",
        "                    total = 0\n",
        "\n",
        "        # Evaluation mode\n",
        "        net.eval()\n",
        "        test_loss = 0\n",
        "        ce_loss = 0\n",
        "        kl_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = net(data)\n",
        "\n",
        "                # Compute loss and update evaluation statistics\n",
        "                if is_bayes:\n",
        "                    ce_loss = loss_func(outputs, target.T[0])\n",
        "                    kl_loss = net.kl_loss()\n",
        "                    loss = ce_loss - beta * kl_loss\n",
        "                else:\n",
        "                    loss = loss_func(outputs, target.T[0])\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += data.shape[0]\n",
        "                correct += predicted.eq(target.T[0]).sum().item()\n",
        "\n",
        "        # Log evaluation statistics\n",
        "        test_acc = 100. * correct / total\n",
        "        test_loss /= len(test_loader)\n",
        "        if is_bayes:\n",
        "            print('Test set: Average loss: {:.4f}, CE loss: {:.4f}, KL loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(\n",
        "                test_loss, ce_loss, kl_loss, test_acc))\n",
        "        else:\n",
        "            print('Test set: Average loss: {:.4f}, Accuracy: {:.4f}'.format(\n",
        "                test_loss,test_acc))"
      ],
      "metadata": {
        "id": "raikcJBO56ad"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = BayesianNeuralNetFC([128, 256, 64], 3 * 28 * 28, 9)\n",
        "train_bayesian_net(net, train_loader, test_loader, is_bayes = True)"
      ],
      "metadata": {
        "id": "BVvMsef_pUZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net= nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.LazyLinear(128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.LazyLinear(256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.LazyLinear(64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.LazyLinear(9),\n",
        "    nn.Softmax(dim = 1)\n",
        ").to(DEVICE)\n",
        "train_bayesian_net(net, train_loader, test_loader)"
      ],
      "metadata": {
        "id": "AAPJIjrhC5es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BayesianNeuralNetConv(nn.Module):\n",
        "    def __init__(self, channel_list, input_channels, n_classes):\n",
        "        super().__init__()\n",
        "        self.inputLayer = BayesianConv2D(input_channels, channel_list[0], k_size=3)\n",
        "        layer_list = []\n",
        "        for i in range(1, len(channel_list)):\n",
        "            layer_list.append(BayesianConv2D(channel_list[i - 1], channel_list[i], k_size=1))\n",
        "        self.convs = nn.ModuleList(layer_list)\n",
        "        self.fc = BayesianDense(channel_list[-1] * 9, n_classes)\n",
        "    \n",
        "    def forward(self, input, sample=False, calculate_log_probs=False):\n",
        "        x = self.inputLayer(input, sample, calculate_log_probs)\n",
        "        x = F.rrelu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, sample, calculate_log_probs)\n",
        "            x = F.rrelu(x)\n",
        "            x = F.max_pool2d(x, 2)\n",
        "        x = nn.Flatten()(x)\n",
        "        x = self.fc(x, sample, calculate_log_probs)\n",
        "        return x\n",
        "    \n",
        "    def kl_loss(self):\n",
        "        kl = 0.0\n",
        "        for layer in self.convs:\n",
        "            kl += layer.kl_loss()\n",
        "        kl += self.inputLayer.kl_loss()\n",
        "        kl += self.fc.kl_loss()\n",
        "        return kl\n"
      ],
      "metadata": {
        "id": "x4efws5kEV6Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = BayesianNeuralNetConv([128, 256, 512], 3, 9)\n",
        "train_bayesian_net(net, train_loader, test_loader, is_bayes = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLfaDJqqyrQL",
        "outputId": "cc487e31-e14a-45ff-9b46-cfaeb3438067"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 704/704 [00:59<00:00, 11.76it/s, accuracy=0.75, ce_loss=0.077734, kl_loss=-117542.554688, loss=0.837853]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.9821, CE loss: 0.6340, KL loss: -1175367.1250, Accuracy: 77.20%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 704/704 [00:58<00:00, 12.00it/s, accuracy=0.80, ce_loss=0.077725, kl_loss=-116911.304688, loss=0.689393]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 1.0101, CE loss: 0.6897, KL loss: -1169098.2500, Accuracy: 73.76%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 704/704 [00:58<00:00, 12.01it/s, accuracy=0.81, ce_loss=0.060770, kl_loss=-116361.023438, loss=0.633698]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 1.1381, CE loss: 0.6932, KL loss: -1163561.7500, Accuracy: 74.51%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction_probabilities(model, test_loader, n=10):\n",
        "    model.eval()\n",
        "    logits = torch.zeros((n, len(test_loader.dataset), model.fc.out_features))\n",
        "    labels = torch.zeros((len(test_loader.dataset)))\n",
        "    with torch.no_grad():\n",
        "        for i in range(n):\n",
        "            for j, (inputs, targets) in enumerate(test_loader):\n",
        "                inputs = inputs.to(DEVICE)\n",
        "                targets = targets.to(DEVICE)\n",
        "                outputs = model(inputs, True, True)\n",
        "                logits[i, j*test_loader.batch_size:(j+1)*test_loader.batch_size] = outputs\n",
        "                labels[j*test_loader.batch_size:(j+1)*test_loader.batch_size] = targets.T[0]\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "    mean_probs = torch.mean(probabilities, dim=0)\n",
        "    predictive_entropy = -torch.sum(mean_probs * torch.log(mean_probs), dim=-1)\n",
        "    return logits, probabilities, predictive_entropy, labels\n",
        "\n",
        "logits, probabilities, predictive_entropy, labels = get_prediction_probabilities(net, test_loader, 10)"
      ],
      "metadata": {
        "id": "nFLiOK420lzv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(logits[:, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BIyuI-lKt6g",
        "outputId": "e14f611c-dd13-49a7-fcaa-2d8941b31b48"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.3357, -2.8012, -3.4424, -7.2041,  3.0641, -1.7646,  0.5326,  1.2331,\n",
            "         -3.1218],\n",
            "        [-2.2026, -2.6125, -3.9419, -6.3811,  3.0603, -2.0508,  0.7576,  0.7787,\n",
            "         -2.8577],\n",
            "        [-2.2714, -2.9328, -3.4846, -6.6636,  2.8130, -1.5303,  0.8061,  1.2011,\n",
            "         -2.9003],\n",
            "        [-2.3162, -2.5014, -3.8882, -6.8814,  3.2804, -1.8435,  0.7750,  0.9494,\n",
            "         -3.0818],\n",
            "        [-2.3098, -2.8382, -3.4280, -7.1369,  3.0445, -1.4302,  0.6599,  1.4373,\n",
            "         -3.0748],\n",
            "        [-2.1641, -2.8708, -3.4462, -7.1711,  3.1172, -1.1977,  0.4775,  1.5482,\n",
            "         -3.1859],\n",
            "        [-2.1828, -2.9823, -3.5555, -7.5515,  3.1620, -1.1902,  0.7007,  1.4106,\n",
            "         -2.9262],\n",
            "        [-1.9803, -2.5128, -3.7384, -6.4184,  3.2800, -1.6811,  0.5380,  1.1982,\n",
            "         -3.2883],\n",
            "        [-2.2732, -2.7890, -3.8550, -6.3579,  3.0107, -1.6099,  0.6252,  1.1661,\n",
            "         -3.1660],\n",
            "        [-2.1451, -2.5705, -3.7246, -6.9516,  3.1551, -1.4519,  0.6970,  1.2088,\n",
            "         -2.9551]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(probabilities[:, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ8Y4faOZwlT",
        "outputId": "f2d15ce2-51c9-4d6b-bbaa-1bc8e6b0e71d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.5888e-03, 2.2531e-03, 1.1866e-03, 2.7582e-05, 7.9445e-01, 6.3531e-03,\n",
            "         6.3189e-02, 1.2732e-01, 1.6352e-03],\n",
            "        [4.2445e-03, 2.8172e-03, 7.4549e-04, 6.5033e-05, 8.1939e-01, 4.9404e-03,\n",
            "         8.1923e-02, 8.3672e-02, 2.2046e-03],\n",
            "        [4.5482e-03, 2.3475e-03, 1.3519e-03, 5.6275e-05, 7.3449e-01, 9.5436e-03,\n",
            "         9.8712e-02, 1.4653e-01, 2.4249e-03],\n",
            "        [3.1073e-03, 2.5820e-03, 6.4514e-04, 3.2341e-05, 8.3743e-01, 4.9849e-03,\n",
            "         6.8371e-02, 8.1400e-02, 1.4450e-03],\n",
            "        [3.5945e-03, 2.1192e-03, 1.1750e-03, 2.8792e-05, 7.6029e-01, 8.6626e-03,\n",
            "         7.0046e-02, 1.5241e-01, 1.6727e-03],\n",
            "        [3.9006e-03, 1.9241e-03, 1.0822e-03, 2.6099e-05, 7.6696e-01, 1.0253e-02,\n",
            "         5.4743e-02, 1.5971e-01, 1.4039e-03],\n",
            "        [3.7227e-03, 1.6735e-03, 9.4346e-04, 1.7349e-05, 7.7993e-01, 1.0045e-02,\n",
            "         6.6546e-02, 1.3535e-01, 1.7701e-03],\n",
            "        [4.3040e-03, 2.5271e-03, 7.4188e-04, 5.0869e-05, 8.2866e-01, 5.8053e-03,\n",
            "         5.3404e-02, 1.0334e-01, 1.1637e-03],\n",
            "        [3.9901e-03, 2.3823e-03, 8.2036e-04, 6.7144e-05, 7.8661e-01, 7.7452e-03,\n",
            "         7.2398e-02, 1.2435e-01, 1.6341e-03],\n",
            "        [3.9929e-03, 2.6092e-03, 8.2280e-04, 3.2646e-05, 8.0004e-01, 7.9855e-03,\n",
            "         6.8485e-02, 1.1425e-01, 1.7761e-03]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiPqS4CWQmAU",
        "outputId": "af9b4ca4-20e0-417c-d63b-6fca9a486c39"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_image_with_probabilities(image, probabilities):\n",
        "    \"\"\"\n",
        "    Displays an RGB image in the left pane and shows the calculated probabilities on the right pane.\n",
        "\n",
        "    Args:\n",
        "    - image: A PyTorch tensor representing the RGB image.\n",
        "    - probabilities: A PyTorch tensor representing the predicted probabilities.\n",
        "\n",
        "    Returns: None\n",
        "    \"\"\"\n",
        "    image = image.detach().cpu().numpy()\n",
        "\n",
        "    # Convert the probabilities tensor to a NumPy array\n",
        "    probabilities = probabilities.detach().cpu().numpy()\n",
        "\n",
        "    # Create a figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(ncols=2)\n",
        "\n",
        "    # Display the image in the left subplot\n",
        "    ax1.imshow(image.transpose(1,2,0))\n",
        "\n",
        "    # Set the title of the left subplot\n",
        "    ax1.set_title('Image')\n",
        "\n",
        "    # Create a bar chart of the probabilities in the right subplot\n",
        "    ax2.barh(range(probabilities.shape[1]), probabilities.squeeze())\n",
        "\n",
        "    # Set the y-axis tick labels to the class names\n",
        "    ax2.set_yticks(range(probabilities.shape[1]))\n",
        "    ax2.set_yticklabels(range(probabilities.shape[1]))\n",
        "\n",
        "    # Set the title of the right subplot\n",
        "    ax2.set_title('Predicted Probabilities')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "nZOcR4AEXZBN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(test_loader))\n",
        "index = np.random.randint(0, 127)\n",
        "image = images[index]\n",
        "label = labels[index]\n",
        "logits = net(image.unsqueeze(0).to(DEVICE))\n",
        "probabilities = torch.softmax(logits, dim=1)\n",
        "display_image_with_probabilities(image, probabilities)\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "iKUinpMl6v4R",
        "outputId": "9d2e1719-e44e-4495-88fb-fdc7707b8559"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import torchmetrics\n",
        "\n",
        "# Define the device\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Define the batch size for the DataLoader\n",
        "targets = []\n",
        "probs = []\n",
        "\n",
        "for images, labels in tqdm(test_loader):\n",
        "    # Move the data to the device\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Get the predicted probabilities from the model\n",
        "    logits = net(images)\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "\n",
        "    # Append the targets and predicted probabilities to the lists.squeeze())\n",
        "    targets.append(labels.detach())\n",
        "    probs.append(probabilities.detach())\n",
        "\n",
        "# Concatenate the targets and predicted probabilities\n",
        "targets = torch.cat(targets).flatten()\n",
        "probs = torch.cat(probs)\n",
        "\n",
        "\n",
        "# Calculate the ECE\n",
        "ece = torchmetrics.functional.classification.multiclass_calibration_error(probs, targets, num_classes=n_classes)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV1_FdH9JIGI",
        "outputId": "00cd5d6d-3bd5-4f77-e7b1-c0744f79d935"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:02<00:00, 11.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7180])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ece)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ODQL7zRJ2d1",
        "outputId": "22d72f2d-1157-420f-8d87-be58b8ac4ec7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0488, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xlFYX5BFk-f4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}